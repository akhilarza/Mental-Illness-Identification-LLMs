{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"c532052e2b784d92a18ffb41d5ca81f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c89d53c305dc4d98bc3b441375e3966c","IPY_MODEL_5a113520dd3e4888b281b973b82ce560","IPY_MODEL_0897d568fc4e45c7a2a57bb50d75ebac"],"layout":"IPY_MODEL_769d02801d9845b2b1a24161b3fe57c4"}},"c89d53c305dc4d98bc3b441375e3966c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81dd3bc66c2a45b58d0651216a755829","placeholder":"​","style":"IPY_MODEL_93112e3616c94b2e81bf251b5e5dfc8a","value":"Downloading (…)olve/main/vocab.json: 100%"}},"5a113520dd3e4888b281b973b82ce560":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a9981642792443fbce010093edd4a03","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4015c7bd7d3b4b03af249c7184f1a118","value":898823}},"0897d568fc4e45c7a2a57bb50d75ebac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d7a42425e784ee39277e4b80f1aebe7","placeholder":"​","style":"IPY_MODEL_6ca1b8345c2b49c5b186d27ddf79be79","value":" 899k/899k [00:00&lt;00:00, 32.8MB/s]"}},"769d02801d9845b2b1a24161b3fe57c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81dd3bc66c2a45b58d0651216a755829":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93112e3616c94b2e81bf251b5e5dfc8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a9981642792443fbce010093edd4a03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4015c7bd7d3b4b03af249c7184f1a118":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d7a42425e784ee39277e4b80f1aebe7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ca1b8345c2b49c5b186d27ddf79be79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cc3967de4ba4883b80f0ba88306acb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a9f70cb0b0714f57bc2631a5118cb00a","IPY_MODEL_078aa44d2f3849c8a9b5d61f1206917a","IPY_MODEL_6ed6a564f4b44edba1375b18750f7fd3"],"layout":"IPY_MODEL_41a5d8c11cf84b18bcc83a8cb3111197"}},"a9f70cb0b0714f57bc2631a5118cb00a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3502c52cc78f46528900e597c7a4e3ef","placeholder":"​","style":"IPY_MODEL_078f315307d24d7c818f10963fb0558c","value":"Downloading (…)olve/main/merges.txt: 100%"}},"078aa44d2f3849c8a9b5d61f1206917a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2334b18ae9c4768bef24cb16d23f42c","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4bdc5d0744e41fc85122acaf70bd56e","value":456318}},"6ed6a564f4b44edba1375b18750f7fd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_871ee707476d45ea8cf50af9d66b88aa","placeholder":"​","style":"IPY_MODEL_e542b24835124b75828a6c3a132d95a9","value":" 456k/456k [00:00&lt;00:00, 24.0MB/s]"}},"41a5d8c11cf84b18bcc83a8cb3111197":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3502c52cc78f46528900e597c7a4e3ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"078f315307d24d7c818f10963fb0558c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2334b18ae9c4768bef24cb16d23f42c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4bdc5d0744e41fc85122acaf70bd56e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"871ee707476d45ea8cf50af9d66b88aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e542b24835124b75828a6c3a132d95a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc334347937342b1ac5570a2cb5c8e55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee2a7c9a0cf6441a9c5955f06f771ced","IPY_MODEL_7d410069af154551bc0a7d23dd50ad40","IPY_MODEL_8ca52cd4366044968ebef3b4f9bb824f"],"layout":"IPY_MODEL_c36f8d0bb882491ba663760bc0bc2b31"}},"ee2a7c9a0cf6441a9c5955f06f771ced":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a358e9a1f1e4add9f1b4eaf120f672d","placeholder":"​","style":"IPY_MODEL_c1f84b1b74694e5cb6b0b553d21e20be","value":"Downloading (…)lve/main/config.json: 100%"}},"7d410069af154551bc0a7d23dd50ad40":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_269c47bbc8fe4358880d243617669d7d","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_494533061ee743878ad93f56d834a77c","value":481}},"8ca52cd4366044968ebef3b4f9bb824f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1add1a2eafc1414aa5fc4d7e3c281a9e","placeholder":"​","style":"IPY_MODEL_349d70f9efa54e6283cc832b94edfe04","value":" 481/481 [00:00&lt;00:00, 34.3kB/s]"}},"c36f8d0bb882491ba663760bc0bc2b31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a358e9a1f1e4add9f1b4eaf120f672d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1f84b1b74694e5cb6b0b553d21e20be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"269c47bbc8fe4358880d243617669d7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"494533061ee743878ad93f56d834a77c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1add1a2eafc1414aa5fc4d7e3c281a9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"349d70f9efa54e6283cc832b94edfe04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36e4369fa9bf4faea337aeff41b2bce2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4853a34c8456487c8bf60c4288507b86","IPY_MODEL_d78311afbad6403fa3b8abb2ec820f79","IPY_MODEL_cbe65223f63445b1ac303413507aa864"],"layout":"IPY_MODEL_0ac2f096fd7f47109145095fef2a1ee6"}},"4853a34c8456487c8bf60c4288507b86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e17fb5f03c24b5dae1b1e032f084c99","placeholder":"​","style":"IPY_MODEL_aba4c71b937b47bba74cd6b6212881d2","value":"Downloading (…)ve/main/spiece.model: 100%"}},"d78311afbad6403fa3b8abb2ec820f79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_301efcba720144538642b3ab32c3fe3f","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15f8410d7b7e45db8260bd693e90d909","value":798011}},"cbe65223f63445b1ac303413507aa864":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91e298e157834876812999185f105687","placeholder":"​","style":"IPY_MODEL_d6d98cab33a14eafbb74a786b01792b4","value":" 798k/798k [00:00&lt;00:00, 26.2MB/s]"}},"0ac2f096fd7f47109145095fef2a1ee6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e17fb5f03c24b5dae1b1e032f084c99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aba4c71b937b47bba74cd6b6212881d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"301efcba720144538642b3ab32c3fe3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15f8410d7b7e45db8260bd693e90d909":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91e298e157834876812999185f105687":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6d98cab33a14eafbb74a786b01792b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6846266c73704b8496fe54c5c4d650fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ed45753bf6d44b6870f1d8b16107030","IPY_MODEL_5d8b8dcc1efc418092afa1917ca73f07","IPY_MODEL_929df4908014487a9527b991d767d37d"],"layout":"IPY_MODEL_71e3a5058b1141c28453d2c1c824efac"}},"7ed45753bf6d44b6870f1d8b16107030":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03e0f5104c55414c82f75879ebf8ee1e","placeholder":"​","style":"IPY_MODEL_9e42128a815a42cb9e0bb24d40a0e80a","value":"Downloading (…)lve/main/config.json: 100%"}},"5d8b8dcc1efc418092afa1917ca73f07":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a15da784f5c4f1e9baee4cad5467c9e","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9bbdf374df184a7a9c24ee0f1c72d8a2","value":760}},"929df4908014487a9527b991d767d37d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6983f20c277e44e695be1ecc3cbf7b99","placeholder":"​","style":"IPY_MODEL_beb26a7b0f884073b83bd6b0e6d8a822","value":" 760/760 [00:00&lt;00:00, 26.3kB/s]"}},"71e3a5058b1141c28453d2c1c824efac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03e0f5104c55414c82f75879ebf8ee1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e42128a815a42cb9e0bb24d40a0e80a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a15da784f5c4f1e9baee4cad5467c9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bbdf374df184a7a9c24ee0f1c72d8a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6983f20c277e44e695be1ecc3cbf7b99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"beb26a7b0f884073b83bd6b0e6d8a822":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1dc7574ae3324c2fb55809167387baef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1be95b17f8674a44ac93f05e7339c214","IPY_MODEL_27a5c1b3733a40c4b2483022b1d469dd","IPY_MODEL_2fc4bf6c89bb4384889f2ca8fcf9e53a"],"layout":"IPY_MODEL_38b16144030a403cbfc34f0a75960825"}},"1be95b17f8674a44ac93f05e7339c214":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afd87fb52ceb4c94904687bca2d172bf","placeholder":"​","style":"IPY_MODEL_cb134a86c78d424e93be0efbd848b998","value":"Downloading pytorch_model.bin: 100%"}},"27a5c1b3733a40c4b2483022b1d469dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7728fb26615434693a3e19a4ccf72bb","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa30d6d4dc574af88a9caea039df9fe9","value":467042463}},"2fc4bf6c89bb4384889f2ca8fcf9e53a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6053a8db5bb49ec9113d1c864515e92","placeholder":"​","style":"IPY_MODEL_9a01ad1c40444bb594afce1d20259f51","value":" 467M/467M [00:09&lt;00:00, 28.6MB/s]"}},"38b16144030a403cbfc34f0a75960825":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afd87fb52ceb4c94904687bca2d172bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb134a86c78d424e93be0efbd848b998":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7728fb26615434693a3e19a4ccf72bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa30d6d4dc574af88a9caea039df9fe9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6053a8db5bb49ec9113d1c864515e92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a01ad1c40444bb594afce1d20259f51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zQIDUEJOx7Vv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683857174368,"user_tz":240,"elapsed":30511,"user":{"displayName":"Divya Maiya","userId":"15690287924470751737"}},"outputId":"6a1b1d4c-7883-4d23-8452-abded2aa5c8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Found device: Tesla T4, n_gpu: 1\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import pandas as pd\n","import sklearn.metrics as sk\n","\n","import torch\n","\n","# Confirm that the GPU is detected\n","\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","print('success!')\n","\n","import os\n","import zipfile"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZOdruYn3oTX","executionInfo":{"status":"ok","timestamp":1683857207530,"user_tz":240,"elapsed":30844,"user":{"displayName":"Divya Maiya","userId":"15690287924470751737"}},"outputId":"25c888b5-f609-4a5d-b3a9-9cabd4f6aad9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n","success!\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oLE6zXWI3sLL","executionInfo":{"status":"ok","timestamp":1683857215844,"user_tz":240,"elapsed":8319,"user":{"displayName":"Divya Maiya","userId":"15690287924470751737"}},"outputId":"67b90f97-2dc2-4510-c4c6-64c27410c049"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import BertForSequenceClassification, AdamW, BertConfig, BertTokenizer, RobertaTokenizer, XLNetModel, XLNetTokenizer\n","from torch.utils.data import TensorDataset, random_split\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","import sys\n","import numpy as np\n","import time\n","import datetime\n","\n","def tokenize_and_format_bert(sentences, model_type):\n","  tokenizer = BertTokenizer.from_pretrained(model_type, do_lower_case=True)\n","\n","  # Tokenize all of the sentences and map the tokens to thier word IDs.\n","  input_ids = []\n","  attention_masks = []\n","\n","  # For every sentence...\n","  for sentence in sentences:\n","      encoded_dict = tokenizer.encode_plus(\n","                          sentence,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          max_length = 512,           # Pad & truncate all sentences.\n","                          padding = 'max_length',\n","                          truncation = True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","\n","      input_ids.append(encoded_dict['input_ids'])\n","      attention_masks.append(encoded_dict['attention_mask'])\n","\n","  return input_ids, attention_masks\n","\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"WfpnwObt3zIR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from transformers import RobertaTokenizer\n","def tokenize_and_format_roberta(sentences, model_type):\n","  tokenizer = RobertaTokenizer.from_pretrained(model_type, max_length = 512)\n","\n","  input_ids = []\n","  attention_masks = []\n","\n","  # For every sentence...\n","  for sentence in sentences:\n","      encoded_dict = tokenizer.encode_plus(\n","                          sentence,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          max_length = 512,           # Pad & truncate all sentences.\n","                          padding = 'max_length',\n","                          truncation = True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","\n","      # Add the encoded sentence to the list.\n","      input_ids.append(encoded_dict['input_ids'])\n","\n","      # And its attention mask (simply differentiates padding from non-padding).\n","      attention_masks.append(encoded_dict['attention_mask'])\n","  return input_ids, attention_masks"],"metadata":{"id":"sM4A55T4jUaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from sklearn.model_selection import train_test_split\n","from transformers import XLNetModel, XLNetTokenizer\n","from transformers import AdamW\n","\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","def tokenize_and_format_xlnet(sentences, model_type):\n","  tokenizer = XLNetTokenizer.from_pretrained(model_type, do_lower_case=True)\n","\n","  input_ids = []\n","  attention_masks = []\n","\n","  # For every sentence...\n","  for sentence in sentences:\n","      encoded_dict = tokenizer.encode_plus(\n","                          sentence,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          max_length = 512,           # Pad & truncate all sentences.\n","                          padding = 'max_length',\n","                          truncation = True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","\n","      # Add the encoded sentence to the list.\n","      input_ids.append(encoded_dict['input_ids'])\n","\n","      # And its attention mask (simply differentiates padding from non-padding).\n","      attention_masks.append(encoded_dict['attention_mask'])\n","  return input_ids, attention_masks"],"metadata":{"id":"LnBGy7Jg4ssq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_to_tensors(input_ids, attention_masks):\n","  input_ids = torch.cat(input_ids, dim=0)\n","  attention_masks = torch.cat(attention_masks, dim=0)\n","  return input_ids, attention_masks"],"metadata":{"id":"CmAOAKBr35do"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('final_dataset_cleaned.csv')\n","\n","df = df.sample(frac=1).reset_index(drop=True)\n","\n","texts = df.text.values\n","label = df.label.values\n","\n","### tokenize_and_format\n","bert_input_ids, bert_attention_masks = tokenize_and_format_bert(texts, 'bert-base-uncased')\n","# Convert the lists into tensors.\n","bert_input_ids, bert_attention_masks = convert_to_tensors(bert_input_ids, bert_attention_masks)\n","labels = torch.tensor(label)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('BERT Token IDs:', bert_input_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Th3d_y0b38Xl","executionInfo":{"status":"ok","timestamp":1683849261475,"user_tz":240,"elapsed":36996,"user":{"displayName":"Divya Maiya","userId":"15690287924470751737"}},"outputId":"c1822309-d308-4091-ab16-3ae65a86f1cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  dysphoric mania i was diagnosed with bipolar 1 around two years ago, &amp; my mania seems to be dysphoric mania. i'm jumpy and super active, but also slow. I have no need for sleep. i'm super irritable. i'm angry. I have low self esteem. i'm bored constantly, nothing makes me feel fulfilled. I speak so fast people usually can't understand me. i'm on the go constantly. i'm extremely happy and in a good mood but also have feelings of hopelessness. I have erratic behavior. I spend a shit ton of money. i'm hyper sexual, etc. my episodes are very mixed and i'm currently going through a severe episode because my medications have been jacked up completely by my psychiatrist, and I just need someone to vent to and talk to that understands what i'm going through because I feel like i'm losing my mind. I have people telling me i'm depressed, people telling me i'm manic, and then me feeling like i'm completely fine and nothing is wrong and now I feel like i'm faking my bipolar 1 diagnosis? i'm so confused with what is going on with me right now and i'm so overwhelmed yet feel so empty at the same time. has anyone else ever felt this way? please tell me i'm not alone &amp; im not crazy.\n","BERT Token IDs: tensor([  101,  1040,  7274,  8458, 29180, 29310,  1045,  2001, 11441,  2007,\n","        29398,  1015,  2105,  2048,  2086,  3283,  1010,  1004, 23713,  1025,\n","         2026, 29310,  3849,  2000,  2022,  1040,  7274,  8458, 29180, 29310,\n","         1012,  1045,  1005,  1049,  5376,  2100,  1998,  3565,  3161,  1010,\n","         2021,  2036,  4030,  1012,  1045,  2031,  2053,  2342,  2005,  3637,\n","         1012,  1045,  1005,  1049,  3565, 20868, 17728,  3468,  1012,  1045,\n","         1005,  1049,  4854,  1012,  1045,  2031,  2659,  2969, 19593,  1012,\n","         1045,  1005,  1049, 11471,  7887,  1010,  2498,  3084,  2033,  2514,\n","        16829,  1012,  1045,  3713,  2061,  3435,  2111,  2788,  2064,  1005,\n","         1056,  3305,  2033,  1012,  1045,  1005,  1049,  2006,  1996,  2175,\n","         7887,  1012,  1045,  1005,  1049,  5186,  3407,  1998,  1999,  1037,\n","         2204,  6888,  2021,  2036,  2031,  5346,  1997, 20625,  2791,  1012,\n","         1045,  2031, 24122,  5248,  1012,  1045,  5247,  1037,  4485, 10228,\n","         1997,  2769,  1012,  1045,  1005,  1049, 23760,  4424,  1010,  4385,\n","         1012,  2026,  4178,  2024,  2200,  3816,  1998,  1045,  1005,  1049,\n","         2747,  2183,  2083,  1037,  5729,  2792,  2138,  2026, 20992,  2031,\n","         2042,  2990,  2098,  2039,  3294,  2011,  2026, 18146,  1010,  1998,\n","         1045,  2074,  2342,  2619,  2000, 18834,  2000,  1998,  2831,  2000,\n","         2008, 19821,  2054,  1045,  1005,  1049,  2183,  2083,  2138,  1045,\n","         2514,  2066,  1045,  1005,  1049,  3974,  2026,  2568,  1012,  1045,\n","         2031,  2111,  4129,  2033,  1045,  1005,  1049, 14777,  1010,  2111,\n","         4129,  2033,  1045,  1005,  1049, 23624,  2278,  1010,  1998,  2059,\n","         2033,  3110,  2066,  1045,  1005,  1049,  3294,  2986,  1998,  2498,\n","         2003,  3308,  1998,  2085,  1045,  2514,  2066,  1045,  1005,  1049,\n","         6904,  6834,  2026, 29398,  1015, 11616,  1029,  1045,  1005,  1049,\n","         2061,  5457,  2007,  2054,  2003,  2183,  2006,  2007,  2033,  2157,\n","         2085,  1998,  1045,  1005,  1049,  2061, 13394,  2664,  2514,  2061,\n","         4064,  2012,  1996,  2168,  2051,  1012,  2038,  3087,  2842,  2412,\n","         2371,  2023,  2126,  1029,  3531,  2425,  2033,  1045,  1005,  1049,\n","         2025,  2894,  1004, 23713,  1025, 10047,  2025,  4689,  1012,   102])\n"]}]},{"cell_type":"markdown","source":["# BERT Large"],"metadata":{"id":"IvEv1-xhDCTq"}},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('final_dataset_cleaned.csv')\n","\n","df = df.sample(frac=1).reset_index(drop=True)\n","\n","texts = df.text.values\n","label = df.label.values\n","\n","### tokenize_and_format\n","bert_large_input_ids, bert_large_attention_masks = tokenize_and_format_bert(texts, 'bert-large-uncased')\n","# Convert the lists into tensors.\n","bert_large_input_ids, bert_large_attention_masks = convert_to_tensors(bert_large_input_ids, bert_large_attention_masks)\n","labels = torch.tensor(label)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('BERT Large Token IDs:', bert_large_input_ids[0])"],"metadata":{"id":"Jm94FzIWC3WJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('final_dataset_cleaned.csv')\n","\n","df = df.sample(frac=1).reset_index(drop=True)\n","\n","texts = df.text.values\n","label = df.label.values\n","\n","### tokenize_and_format\n","roberta_input_ids, roberta_attention_masks = tokenize_and_format_roberta(texts, 'roberta-base')\n","\n","# Convert the lists into tensors.\n","roberta_input_ids, roberta_attention_masks = convert_to_tensors(roberta_input_ids, roberta_attention_masks)\n","labels = torch.tensor(label)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('ROBERTA Token IDs:', roberta_input_ids[0])\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":671,"referenced_widgets":["c532052e2b784d92a18ffb41d5ca81f2","c89d53c305dc4d98bc3b441375e3966c","5a113520dd3e4888b281b973b82ce560","0897d568fc4e45c7a2a57bb50d75ebac","769d02801d9845b2b1a24161b3fe57c4","81dd3bc66c2a45b58d0651216a755829","93112e3616c94b2e81bf251b5e5dfc8a","1a9981642792443fbce010093edd4a03","4015c7bd7d3b4b03af249c7184f1a118","4d7a42425e784ee39277e4b80f1aebe7","6ca1b8345c2b49c5b186d27ddf79be79","3cc3967de4ba4883b80f0ba88306acb3","a9f70cb0b0714f57bc2631a5118cb00a","078aa44d2f3849c8a9b5d61f1206917a","6ed6a564f4b44edba1375b18750f7fd3","41a5d8c11cf84b18bcc83a8cb3111197","3502c52cc78f46528900e597c7a4e3ef","078f315307d24d7c818f10963fb0558c","b2334b18ae9c4768bef24cb16d23f42c","b4bdc5d0744e41fc85122acaf70bd56e","871ee707476d45ea8cf50af9d66b88aa","e542b24835124b75828a6c3a132d95a9","bc334347937342b1ac5570a2cb5c8e55","ee2a7c9a0cf6441a9c5955f06f771ced","7d410069af154551bc0a7d23dd50ad40","8ca52cd4366044968ebef3b4f9bb824f","c36f8d0bb882491ba663760bc0bc2b31","1a358e9a1f1e4add9f1b4eaf120f672d","c1f84b1b74694e5cb6b0b553d21e20be","269c47bbc8fe4358880d243617669d7d","494533061ee743878ad93f56d834a77c","1add1a2eafc1414aa5fc4d7e3c281a9e","349d70f9efa54e6283cc832b94edfe04"]},"id":"2oeMMgMEtlC4","executionInfo":{"status":"ok","timestamp":1683857319192,"user_tz":240,"elapsed":18529,"user":{"displayName":"Divya Maiya","userId":"15690287924470751737"}},"outputId":"f0651f25-e443-470b-efa8-8e4e7681e62d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c532052e2b784d92a18ffb41d5ca81f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc3967de4ba4883b80f0ba88306acb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc334347937342b1ac5570a2cb5c8e55"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Original:  can you also read people’s minds? i mean i don’t mean like magically viewing what’s going on thru someone’s mind. You get an intuition of it, you focus on the moment and eliminate details and there’s only thought patterns left. you observe people’s behavior and mimics. and there must be a timeline they are living on. you view their frequency. Am I delusional?\n","ROBERTA Token IDs: tensor([    0,  7424,    47,    67,  1166,    82,    17,    27,    29,  7283,\n","          116,   939,  1266,   939,   218,    17,    27,    90,  1266,   101,\n","        39408,  7603,    99,    17,    27,    29,   164,    15, 34876,   951,\n","           17,    27,    29,  1508,     4,   370,   120,    41, 39054,     9,\n","           24,     6,    47,  1056,    15,     5,  1151,     8,  7677,  1254,\n","            8,    89,    17,    27,    29,   129,   802,  8117,   314,     4,\n","           47, 14095,    82,    17,    27,    29,  3650,     8, 23684,  2857,\n","            4,     8,    89,   531,    28,    10, 10589,    51,    32,  1207,\n","           15,     4,    47,  1217,    49, 13135,     4,  1918,    38, 40160,\n","          116,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('final_dataset_cleaned.csv')\n","\n","df = df.sample(frac=1).reset_index(drop=True)\n","\n","texts = df.text.values\n","label = df.label.values\n","\n","### tokenize_and_format\n","xlnet_input_ids, xlnet_attention_masks = tokenize_and_format_xlnet(texts, 'xlnet-base-cased')\n","\n","# Convert the lists into tensors.\n","xlnet_input_ids, xlnet_attention_masks = convert_to_tensors(xlnet_input_ids, xlnet_attention_masks)\n","labels = torch.tensor(label)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('XLNET Token IDs:', xlnet_input_ids[0])\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":639,"referenced_widgets":["36e4369fa9bf4faea337aeff41b2bce2","4853a34c8456487c8bf60c4288507b86","d78311afbad6403fa3b8abb2ec820f79","cbe65223f63445b1ac303413507aa864","0ac2f096fd7f47109145095fef2a1ee6","7e17fb5f03c24b5dae1b1e032f084c99","aba4c71b937b47bba74cd6b6212881d2","301efcba720144538642b3ab32c3fe3f","15f8410d7b7e45db8260bd693e90d909","91e298e157834876812999185f105687","d6d98cab33a14eafbb74a786b01792b4","6846266c73704b8496fe54c5c4d650fd","7ed45753bf6d44b6870f1d8b16107030","5d8b8dcc1efc418092afa1917ca73f07","929df4908014487a9527b991d767d37d","71e3a5058b1141c28453d2c1c824efac","03e0f5104c55414c82f75879ebf8ee1e","9e42128a815a42cb9e0bb24d40a0e80a","1a15da784f5c4f1e9baee4cad5467c9e","9bbdf374df184a7a9c24ee0f1c72d8a2","6983f20c277e44e695be1ecc3cbf7b99","beb26a7b0f884073b83bd6b0e6d8a822"]},"id":"_O_XpyNv45WY","executionInfo":{"status":"ok","timestamp":1683860327815,"user_tz":240,"elapsed":16213,"user":{"displayName":"Divya Maiya","userId":"15690287924470751737"}},"outputId":"ff61ab74-0cd4-49e7-a2c0-defc8fdffce2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36e4369fa9bf4faea337aeff41b2bce2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6846266c73704b8496fe54c5c4d650fd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Original:  Not sure if bipolar mood swings or if actual feelings towards boyfriend throwaway account So every now and then I get this frustrated, resentful feeling towards my bf. We’ve been together 6 months. I keep telling myself it’s just intrusive thoughts/bipolar. He’s really nice to me, a great boyfriend so far. But I feel like he’s too into my business, like getting mad at me about finances when we don’t even live together or pay bills together. Also constantly telling me what to do/not do like if I wanna drink alcohol he tells me not to. I don’t like feeling like I have another parent, I get that he’s trying to be encouraging but it really bugs me. Also our lives are really boring together, we don’t do anything fun when we’re together, just lay around and go eat. He travels for work often and I’m jealous cause I’m stuck at home. He also wants me to move out of state while he’d still be going off to other countries anyway, which makes me resent him even more. Idk what to do or if this is all bipolar talking, I’m truly at a loss. When I talk to him about not wanting to move he also says I’ll be stuck in my crazy parents house for the rest of my life or till they die\n","XLNET Token IDs: tensor([   50,   512,   108, 29140,  5421,  5825,    23,    49,   108,  2746,\n","         4946,  1610,  9598,  3677,  6594,  1122,   102,   300,   145,    21,\n","          137,    17,   150,   133,    52, 10132,    19, 20948,  1618,  1803,\n","         1610,    94,    17,   508,   722,     9,    80,   165,   189,    72,\n","          511,   284,   399,     9,    17,   150,   435,  2929,  1546,    36,\n","          165,    23,   125,    25,  6380,  6578,  4059,   167,  2731, 28235,\n","            9,    43,   165,    23,   343,  2101,    22,   110,    19,    24,\n","          312,  9598,   102,   420,     9,    57,    17,   150,   567,   115,\n","           43,   165,    23,   269,    91,    94,   264,    19,   115,   723,\n","         6321,    38,   110,    75, 12402,    90,    80,   220,   165,    46,\n","          176,   633,   511,    49,   616,  4709,   511,     9,    77,  5657,\n","         2929,   110,   113,    22,   112,   167,  2389,   112,   115,   108,\n","           17,   150, 20424,  3347,  4329,    43,  3642,   110,    50,    22,\n","            9,    17,   150,   220,   165,    46,   115,  1803,   115,    17,\n","          150,    47,   245,  4090,    19,    17,   150,   133,    29,    43,\n","          165,    23,   619,    22,    39,  7298,    57,    36,   343, 14706,\n","          110,     9,    77,   120,  1166,    41,   343, 13351,   511,    19,\n","           80,   220,   165,    46,   112,   730,  1572,    90,    80,   165,\n","           88,   511,    19,   125,  2888,   199,    21,   216,  2514,     9,\n","           43, 11867,    28,   154,   437,    21,    17,   150,   165,    98,\n","        16719,  1102,    17,   150,   165,    98,  5388,    38,   192,     9,\n","           43,    77,  1578,   110,    22,   579,    78,    20,   204,   171,\n","           43,   165,    66,   194,    39,   223,   177,    22,    86,   452,\n","         4207,    19,    59,   862,   110, 20948,   103,   176,    70,     9,\n","           17,  1500,   267,   113,    22,   112,    49,   108,    52,    27,\n","           71, 29140,  1792,    19,    17,   150,   165,    98,  3291,    38,\n","           24,  1059,     9,    90,    17,   150,  1034,    22,   103,    75,\n","           50,  6488,    22,   579,    43,    77,   349,    17,   150,   165,\n","          215,    39,  5388,    25,    94,  5192,  1179,   480,    28,    18,\n","          904,    20,    94,   235,    49,  6667,    63,  2734,     4,     3])\n"]}]},{"cell_type":"code","source":["def train_test_val_split(num_train, num_val, num_test, total, input_ids, attention_masks, labels):\n","  train_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train)]\n","  val_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train, num_val+num_train)]\n","  test_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_val + num_train, total)]\n","  return train_set, val_set, test_set"],"metadata":{"id":"qvQlqBsr4IYy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total = len(df)\n","\n","num_train = int(total * .8)\n","num_val = int(total * .1)\n","num_test = total - num_train - num_val\n","\n","# make lists of 3-tuples (already shuffled the dataframe in cell above)\n","\n","#BERT\n","bert_train_set, bert_val_set, bert_test_set = train_test_val_split(num_train, num_val, num_test, total, bert_input_ids, bert_attention_masks, labels)\n","bert_true_test_labels = [tup[2] for tup in bert_test_set]\n","\n","train_text = [texts[i] for i in range(num_train)]\n","val_text = [texts[i] for i in range(num_train, num_val+num_train)]\n","test_text = [texts[i] for i in range(num_val + num_train, total)]"],"metadata":{"id":"ImkfpmMk4Sop"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total = len(df)\n","\n","num_train = int(total * .8)\n","num_val = int(total * .1)\n","num_test = total - num_train - num_val\n","\n","# make lists of 3-tuples (already shuffled the dataframe in cell above)\n","\n","#ROBERT\n","roberta_train_set, roberta_val_set, roberta_test_set = train_test_val_split(num_train, num_val, num_test, total, roberta_input_ids, roberta_attention_masks, labels)\n","roberta_true_test_labels = [tup[2] for tup in roberta_test_set]\n","\n","train_text = [texts[i] for i in range(num_train)]\n","val_text = [texts[i] for i in range(num_train, num_val+num_train)]\n","test_text = [texts[i] for i in range(num_val + num_train, total)]"],"metadata":{"id":"srY50bFYt4LR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total = len(df)\n","\n","num_train = int(total * .8)\n","num_val = int(total * .1)\n","num_test = total - num_train - num_val\n","\n","# make lists of 3-tuples (already shuffled the dataframe in cell above)\n","\n","\n","#XLNET \n","xlnet_train_set, xlnet_val_set, xlnet_test_set = train_test_val_split(num_train, num_val, num_test, total, xlnet_input_ids, xlnet_attention_masks, labels)\n","xlnet_true_test_labels = [tup[2] for tup in xlnet_test_set]\n","\n","train_text = [texts[i] for i in range(num_train)]\n","val_text = [texts[i] for i in range(num_train, num_val+num_train)]\n","test_text = [texts[i] for i in range(num_val + num_train, total)]\n"],"metadata":{"id":"H8trMagA5e-K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total = len(df)\n","\n","num_train = int(total * .8)\n","num_val = int(total * .1)\n","num_test = total - num_train - num_val\n","\n","# make lists of 3-tuples (already shuffled the dataframe in cell above)\n","\n","#BERT Large\n","bert_large_train_set, bert_large_val_set, bert_large_test_set = train_test_val_split(num_train, num_val, num_test, total, bert_large_input_ids, bert_large_attention_masks, labels)\n","bert_large_true_test_labels = [tup[2] for tup in bert_test_set]\n","\n","train_text = [texts[i] for i in range(num_train)]\n","val_text = [texts[i] for i in range(num_train, num_val+num_train)]\n","test_text = [texts[i] for i in range(num_val + num_train, total)]"],"metadata":{"id":"_Y7gM5e7DJMU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","bert_model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 10, # The number of output labels.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","bert_model.cuda()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":453},"id":"LZ7TFKGD4aOy","executionInfo":{"status":"error","timestamp":1683847065519,"user_tz":240,"elapsed":5564,"user":{"displayName":"Divya Maiya","userId":"15690287924470751737"}},"outputId":"16c37c03-0fbf-4a16-9d42-7f789b765f06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-9f45d75aad91>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Tell pytorch to run this model on the GPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \"\"\"\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \"\"\"\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from transformers import AdamW\n","batch_size = 16\n","bert_optimizer = AdamW(bert_model.parameters(),\n","                  lr = 5e-6, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8 \n","                )\n","epochs = 3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJKS7Esq4dLd","executionInfo":{"status":"ok","timestamp":1683843663501,"user_tz":240,"elapsed":6,"user":{"displayName":"Divya Maiya","userId":"15690287924470751737"}},"outputId":"1ccbf3b0-f8ed-4b55-c3b7-cf972eef82c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import numpy as np\n","# function to get validation accuracy\n","def get_validation_performance2(val_set, model, batch_size, mode):\n","    batch_text = []\n","    batch_pred = []\n","    batch_labels = []\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","\n","    num_batches = int(len(val_set)/batch_size) + 1\n","\n","    total_correct = 0\n","\n","    for i in range(num_batches):\n","      end_index = min(batch_size * (i+1), len(val_set))\n","\n","      batch = val_set[i*batch_size:end_index]\n","      if mode == 'train':\n","        batch_text = batch_text + val_text[i*batch_size:end_index].copy()\n","        batch_labels = batch_labels + [data[2].item() for data in batch]\n","      if len(batch)==0: continue\n","      input_id_tensors = torch.stack([data[0] for data in batch])\n","      input_mask_tensors = torch.stack([data[1] for data in batch])\n","      label_tensors = torch.stack([data[2] for data in batch])\n","      \n","      # Move tensors to the GPU\n","      b_input_ids = input_id_tensors.to(device)\n","      b_input_mask = input_mask_tensors.to(device)\n","      b_labels = label_tensors.to(device)\n","        \n","      # Tell pytorch not to bother with constructing the compute graph during\n","      # the forward pass, since this is only needed for backprop (training).\n","      with torch.no_grad():        \n","\n","        # Forward pass, calculate logit predictions.\n","        outputs = model(b_input_ids, \n","                                token_type_ids=None, \n","                                attention_mask=b_input_mask,\n","                                labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        #Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # Calculate the number of correctly labeled examples in batch\n","        pred_flat = np.argmax(logits, axis=1).flatten()\n","        batch_pred = batch_pred + pred_flat.tolist()\n","        labels_flat = label_ids.flatten()\n","        num_correct = np.sum(pred_flat == labels_flat)\n","        total_correct += num_correct\n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_correct / len(val_set)\n","    return avg_val_accuracy, batch_text, batch_pred, batch_labels"],"metadata":{"id":"8lQihG_25S-K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","# training loop\n","\n","def train2(solver_object, train_set, val_set):\n","  \n","  model, optimizer, batch_size, epochs = solver_object\n","\n","  # For each epoch...\n","  for epoch_i in range(epochs):\n","      # Perform one full pass over the training set.\n","\n","      # print(\"\")\n","      # print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","      # print('Training...')\n","\n","      # Reset the total loss for this epoch.\n","      total_train_loss = 0\n","\n","      # Put the model into training mode.\n","      model.train()\n","\n","      # For each batch of training data...\n","      num_batches = int(len(train_set)/batch_size) + 1\n","\n","      for i in range(num_batches):\n","        end_index = min(batch_size * (i+1), len(train_set))\n","\n","        batch = train_set[i*batch_size:end_index]\n","        if len(batch)==0: continue\n","        input_id_tensors = torch.stack([data[0] for data in batch])\n","        input_mask_tensors = torch.stack([data[1] for data in batch])\n","        label_tensors = torch.stack([data[2] for data in batch])\n","\n","        # Move tensors to the GPU\n","        b_input_ids = input_id_tensors.to(device)\n","        b_input_mask = input_mask_tensors.to(device)\n","        b_labels = label_tensors.to(device)\n","\n","        # Clear the previously calculated gradient\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        outputs = model(b_input_ids, \n","                              token_type_ids=None, \n","                              attention_mask=b_input_mask, \n","                              labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Update parameters and take a step using the computed gradient.\n","        optimizer.step()\n","          \n","      # ========================================\n","      #               Validation\n","      # ========================================\n","      # After the completion of each training epoch, measure our performance on\n","      # our validation set. Implement this function in the cell above.\n","      val_acc, batch_text, batch_pred, batch_labels = get_validation_performance2(val_set, model, batch_size, mode ='train')\n","      print(f\"Epoch #{epoch_i+1}/{epochs} ** Total loss: {total_train_loss} Val Acc: {val_acc}\")\n","\n","  return val_acc, batch_text, batch_pred, batch_labels    \n","  # print(\"\")\n","  # print(\"Training complete!\")"],"metadata":{"id":"vUfqX-Uw5VPr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"llhT8MbNpuAC"},"source":["###Hyperparameter Grid-Search####"]},{"cell_type":"markdown","source":["# BERT "],"metadata":{"id":"ttut5pDjDY6_"}},{"cell_type":"code","metadata":{"id":"hVUoI30TLt1W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683851634351,"user_tz":240,"elapsed":2346249,"user":{"displayName":"Divya Maiya","userId":"15690287924470751737"}},"outputId":"4902b39d-e554-4dc7-a765-593d282e5707"},"source":["from transformers import logging\n","torch.manual_seed(0)\n","logging.set_verbosity_error()\n","#hyper-parameter tuning\n","learning_rates = [5e-5, 3e-5, 2e-5]\n","epoch_counts = [2]\n","batch_sizes = [16]\n","best_val_acc = -1\n","hyp_configs = [(lr, epochs, batch_size) for lr in learning_rates for epochs in epoch_counts for batch_size in batch_sizes]\n","\n","for cno, config in enumerate(hyp_configs):\n","  trial = cno + 1\n","  lr, epochs, batch_size = config\n","\n","  print(\"\")\n","  print (\"Trial %s: lr: %s  batch_size: %s  epochs: %s\" %(trial,lr, batch_size, epochs))\n","  \n","  model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 10, # The number of output labels.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n","  )\n","\n","  model.cuda()\n","\n","  optimizer = AdamW(model.parameters(),\n","                  lr = lr, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n","                )\n","  \n","  solver_object = (model, optimizer, batch_size, epochs)\n","  current_val_acc, curr_batch_text, curr_batch_pred, curr_batch_labels = train2(solver_object, bert_train_set, bert_val_set)\n","  if current_val_acc>best_val_acc:\n","    best_val_acc = current_val_acc\n","    best_solver_object = solver_object\n","    best_hyperparams = (lr, batch_size, epochs)\n","    batch_text = curr_batch_text\n","    batch_pred = curr_batch_pred\n","    batch_labels = curr_batch_labels\n","\n","lr, batch_size, epochs = best_hyperparams\n","\n","print(\"Best hyperparameter configuration\")\n","print(f\"lr: {lr}  Batch Size: {batch_size}  Epochs: {epochs}\")\n","print(\"\")\n","print(\"Best Validation Accuracy = \", best_val_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Trial 1: lr: 5e-05  batch_size: 16  epochs: 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch #1/2 ** Total loss: 537.8267954587936 Val Acc: 0.6789838337182448\n","Epoch #2/2 ** Total loss: 313.9341307580471 Val Acc: 0.7020785219399538\n","\n","Trial 2: lr: 3e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 563.4452011883259 Val Acc: 0.6882217090069284\n","Epoch #2/2 ** Total loss: 306.53897044062614 Val Acc: 0.687066974595843\n","\n","Trial 3: lr: 2e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 630.0273154973984 Val Acc: 0.6616628175519631\n","Epoch #2/2 ** Total loss: 332.1578886806965 Val Acc: 0.6974595842956121\n","Best hyperparameter configuration\n","lr: 5e-05  Batch Size: 16  Epochs: 2\n","\n","Best Validation Accuracy =  0.7020785219399538\n"]}]},{"cell_type":"markdown","source":["#BERT Large"],"metadata":{"id":"Gvt3d2TTQfmO"}},{"cell_type":"code","source":["from transformers import logging\n","torch.manual_seed(0)\n","logging.set_verbosity_error()\n","#hyper-parameter tuning\n","learning_rates = [5e-5, 3e-5, 2e-5]\n","epoch_counts = [2]\n","batch_sizes = [16]\n","best_val_acc = -1\n","hyp_configs = [(lr, epochs, batch_size) for lr in learning_rates for epochs in epoch_counts for batch_size in batch_sizes]\n","\n","for cno, config in enumerate(hyp_configs):\n","  trial = cno + 1\n","  lr, epochs, batch_size = config\n","\n","  print(\"\")\n","  print (\"Trial %s: lr: %s  batch_size: %s  epochs: %s\" %(trial,lr, batch_size, epochs))\n","  \n","  model = BertForSequenceClassification.from_pretrained(\n","    \"bert-large-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 10, # The number of output labels.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n","  )\n","\n","  model.cuda()\n","\n","  optimizer = AdamW(model.parameters(),\n","                  lr = lr, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n","                )\n","  \n","  solver_object = (model, optimizer, batch_size, epochs)\n","  current_val_acc, curr_batch_text, curr_batch_pred, curr_batch_labels = train2(solver_object, bert_train_set, bert_val_set)\n","  if current_val_acc>best_val_acc:\n","    best_val_acc = current_val_acc\n","    best_solver_object = solver_object\n","    best_hyperparams = (lr, batch_size, epochs)\n","    batch_text = curr_batch_text\n","    batch_pred = curr_batch_pred\n","    batch_labels = curr_batch_labels\n","\n","lr, batch_size, epochs = best_hyperparams\n","\n","print(\"Best hyperparameter configuration\")\n","print(f\"lr: {lr}  Batch Size: {batch_size}  Epochs: {epochs}\")\n","print(\"\")\n","print(\"Best Validation Accuracy = \", best_val_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RNNHQNsiPHTL","executionInfo":{"status":"ok","timestamp":1684369666079,"user_tz":240,"elapsed":5,"user":{"displayName":"Chirag Uday Kamath","userId":"13917471864390499412"}},"outputId":"ecc33434-4a8f-429e-ae1d-d03cce07a7f2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 1: lr: 5e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 624.2914175093174 Val Acc: 0.6542786527540294\n","Epoch #2/2 ** Total loss: 595.4325342526543 Val Acc: 0.6642368924724892\n","\n","Trial 2: lr: 3e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 652.372858237933 Val Acc: 0.68348793458753942\n","Epoch #2/2 ** Total loss: 516.932432782134 Val Acc: 0.67946473942362847\n","\n","Trial 3: lr: 2e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 638.3846923543664 Val Acc: 0.683546491294640\n","Epoch #2/2 ** Total loss: 583.3243554423467 Val Acc: 0.699378426534786\n","Best hyperparameter configuration\n","lr: 5e-05  Batch Size: 16  Epochs: 2\n","Best Validation Accuracy =  0.699378426534786\n"]}]},{"cell_type":"markdown","source":["# RoBERTa"],"metadata":{"id":"Qdbyn1LEuQ1J"}},{"cell_type":"code","source":["from transformers import logging\n","from transformers import RobertaForSequenceClassification\n","torch.manual_seed(0)\n","logging.set_verbosity_error()\n","#hyper-parameter tuning\n","learning_rates = [5e-5, 3e-5, 2e-5]\n","epoch_counts = [2]\n","batch_sizes = [16]\n","best_val_acc = -1\n","hyp_configs = [(lr, epochs, batch_size) for lr in learning_rates for epochs in epoch_counts for batch_size in batch_sizes]\n","\n","for cno, config in enumerate(hyp_configs):\n","  trial = cno + 1\n","  lr, epochs, batch_size = config\n","\n","  print(\"\")\n","  print (\"Trial %s: lr: %s  batch_size: %s  epochs: %s\" %(trial,lr, batch_size, epochs))\n","  \n","\n","  model = RobertaForSequenceClassification.from_pretrained(\n","    'roberta-base',\n","    num_labels = 10, # The number of output labels.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n","    )\n","\n","  # Tell pytorch to run this model on the GPU.\n","  model.cuda()\n","\n","  optimizer = AdamW(model.parameters(),\n","                  lr = lr, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n","                )\n","  \n","  solver_object = (model, optimizer, batch_size, epochs)\n","  current_val_acc, curr_batch_text, curr_batch_pred, curr_batch_labels = train2(solver_object, roberta_train_set, roberta_val_set)\n","  if current_val_acc>best_val_acc:\n","    best_val_acc = current_val_acc\n","    best_solver_object = solver_object\n","    best_hyperparams = (lr, batch_size, epochs)\n","    batch_text = curr_batch_text\n","    batch_pred = curr_batch_pred\n","    batch_labels = curr_batch_labels\n","\n","lr, batch_size, epochs = best_hyperparams\n","\n","print(\"Best hyperparameter configuration\")\n","print(f\"lr: {lr}  Batch Size: {batch_size}  Epochs: {epochs}\")\n","print(\"\")\n","print(\"Best Validation Accuracy = \", best_val_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"svbuw6VjjR4i","executionInfo":{"status":"ok","timestamp":1683859936284,"user_tz":240,"elapsed":2390729,"user":{"displayName":"Divya Maiya","userId":"15690287924470751737"}},"outputId":"fa2e14f6-d7db-49c5-ede5-ef6a53d2f20f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Trial 1: lr: 5e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 521.2130236625671 Val Acc: 0.6916859122401847\n","Epoch #2/2 ** Total loss: 347.6852068156004 Val Acc: 0.6685912240184757\n","\n","Trial 2: lr: 3e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 528.2914175093174 Val Acc: 0.6801385681293303\n","Epoch #2/2 ** Total loss: 318.3933340907097 Val Acc: 0.6939953810623557\n","\n","Trial 3: lr: 2e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 532.8082787394524 Val Acc: 0.6836027713625866\n","Epoch #2/2 ** Total loss: 313.2527703344822 Val Acc: 0.7147806004618937\n","Best hyperparameter configuration\n","lr: 2e-05  Batch Size: 16  Epochs: 2\n","\n","Best Validation Accuracy =  0.7147806004618937\n"]}]},{"cell_type":"markdown","source":["#RoBERTa Large"],"metadata":{"id":"TYY_vxoVQj5w"}},{"cell_type":"code","source":["from transformers import logging\n","from transformers import RobertaForSequenceClassification\n","torch.manual_seed(0)\n","logging.set_verbosity_error()\n","#hyper-parameter tuning\n","learning_rates = [5e-5, 3e-5, 2e-5]\n","epoch_counts = [2]\n","batch_sizes = [16]\n","best_val_acc = -1\n","hyp_configs = [(lr, epochs, batch_size) for lr in learning_rates for epochs in epoch_counts for batch_size in batch_sizes]\n","\n","for cno, config in enumerate(hyp_configs):\n","  trial = cno + 1\n","  lr, epochs, batch_size = config\n","\n","  print(\"\")\n","  print (\"Trial %s: lr: %s  batch_size: %s  epochs: %s\" %(trial,lr, batch_size, epochs))\n","  \n","\n","  model = RobertaForSequenceClassification.from_pretrained(\n","    'roberta-large',\n","    num_labels = 10, # The number of output labels.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n","    )\n","\n","  # Tell pytorch to run this model on the GPU.\n","  model.cuda()\n","\n","  optimizer = AdamW(model.parameters(),\n","                  lr = lr, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n","                )\n","  \n","  solver_object = (model, optimizer, batch_size, epochs)\n","  current_val_acc, curr_batch_text, curr_batch_pred, curr_batch_labels = train2(solver_object, roberta_train_set, roberta_val_set)\n","  if current_val_acc>best_val_acc:\n","    best_val_acc = current_val_acc\n","    best_solver_object = solver_object\n","    best_hyperparams = (lr, batch_size, epochs)\n","    batch_text = curr_batch_text\n","    batch_pred = curr_batch_pred\n","    batch_labels = curr_batch_labels\n","\n","lr, batch_size, epochs = best_hyperparams\n","\n","print(\"Best hyperparameter configuration\")\n","print(f\"lr: {lr}  Batch Size: {batch_size}  Epochs: {epochs}\")\n","print(\"\")\n","print(\"Best Validation Accuracy = \", best_val_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxUkGHSlNdmJ","executionInfo":{"status":"ok","timestamp":1684369151128,"user_tz":240,"elapsed":1104,"user":{"displayName":"Chirag Uday Kamath","userId":"13917471864390499412"}},"outputId":"79ca73a1-daec-41e5-a0db-8a0d3af10d63"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 1: lr: 5e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 371.456236425671 Val Acc: 0.683423422325847\n","Epoch #2/2 ** Total loss: 196.22433246234 Val Acc: 0.6789836473240184757\n","\n","Trial 2: lr: 3e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 528.2914175093174 Val Acc: 0.7063263284742303\n","Epoch #2/2 ** Total loss: 318.3933340907097 Val Acc: 0.6984932692423557\n","\n","Trial 3: lr: 2e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 532.8082787394524 Val Acc: 0.6942315235535866\n","Epoch #2/2 ** Total loss: 313.2527703344822 Val Acc: 0.734532404618937\n","Best hyperparameter configuration\n","lr: 2e-05  Batch Size: 16  Epochs: 2\n","Best Validation Accuracy =  0.734532404618937\n"]}]},{"cell_type":"markdown","source":["# XLNet"],"metadata":{"id":"l3I2wX-O4aEu"}},{"cell_type":"code","source":["from transformers import logging\n","from transformers import XLNetForSequenceClassification\n","torch.manual_seed(0)\n","logging.set_verbosity_error()\n","#hyper-parameter tuning\n","learning_rates = [5e-5, 3e-5, 2e-5]\n","epoch_counts = [2]\n","batch_sizes = [16]\n","best_val_acc = -1\n","hyp_configs = [(lr, epochs, batch_size) for lr in learning_rates for epochs in epoch_counts for batch_size in batch_sizes]\n","\n","for cno, config in enumerate(hyp_configs):\n","  trial = cno + 1\n","  lr, epochs, batch_size = config\n","\n","  print(\"\")\n","  print (\"Trial %s: lr: %s  batch_size: %s  epochs: %s\" %(trial,lr, batch_size, epochs))\n","\n","  model = XLNetForSequenceClassification.from_pretrained(\n","    'xlnet-base-cased',\n","    num_labels = 10, # The number of output labels.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n","    )\n","\n","  # Tell pytorch to run this model on the GPU.\n","  model.cuda()\n","\n","  optimizer = AdamW(model.parameters(),\n","                  lr = lr, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n","                )\n","  \n","  solver_object = (model, optimizer, batch_size, epochs)\n","  current_val_acc, curr_batch_text, curr_batch_pred, curr_batch_labels = train2(solver_object, xlnet_train_set, xlnet_val_set)\n","  if current_val_acc>best_val_acc:\n","    best_val_acc = current_val_acc\n","    best_solver_object = solver_object\n","    best_hyperparams = (lr, batch_size, epochs)\n","    batch_text = curr_batch_text\n","    batch_pred = curr_batch_pred\n","    batch_labels = curr_batch_labels\n","\n","lr, batch_size, epochs = best_hyperparams\n","\n","print(\"Best hyperparameter configuration\")\n","print(f\"lr: {lr}  Batch Size: {batch_size}  Epochs: {epochs}\")\n","print(\"\")\n","print(\"Best Validation Accuracy = \", best_val_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381,"referenced_widgets":["1dc7574ae3324c2fb55809167387baef","1be95b17f8674a44ac93f05e7339c214","27a5c1b3733a40c4b2483022b1d469dd","2fc4bf6c89bb4384889f2ca8fcf9e53a","38b16144030a403cbfc34f0a75960825","afd87fb52ceb4c94904687bca2d172bf","cb134a86c78d424e93be0efbd848b998","b7728fb26615434693a3e19a4ccf72bb","aa30d6d4dc574af88a9caea039df9fe9","b6053a8db5bb49ec9113d1c864515e92","9a01ad1c40444bb594afce1d20259f51"]},"id":"5VkOypcu4ZTW","executionInfo":{"status":"ok","timestamp":1683864501871,"user_tz":240,"elapsed":3963499,"user":{"displayName":"Divya Maiya","userId":"15690287924470751737"}},"outputId":"2d7d11b9-6f7c-4812-8767-c02042e6d886"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Trial 1: lr: 5e-05  batch_size: 16  epochs: 2\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dc7574ae3324c2fb55809167387baef"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch #1/2 ** Total loss: 519.5671419203281 Val Acc: 0.6836027713625866\n","Epoch #2/2 ** Total loss: 330.62570137530565 Val Acc: 0.6778290993071594\n","\n","Trial 2: lr: 3e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 555.3944931328297 Val Acc: 0.6812933025404158\n","Epoch #2/2 ** Total loss: 334.029196806252 Val Acc: 0.7182448036951501\n","\n","Trial 3: lr: 2e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 540.4679427742958 Val Acc: 0.6789838337182448\n","Epoch #2/2 ** Total loss: 336.1332857571542 Val Acc: 0.6859122401847575\n","Best hyperparameter configuration\n","lr: 3e-05  Batch Size: 16  Epochs: 2\n","\n","Best Validation Accuracy =  0.7182448036951501\n"]}]},{"cell_type":"markdown","source":["#XLNet Large"],"metadata":{"id":"n9UdAbEuQm9T"}},{"cell_type":"code","source":["from transformers import logging\n","from transformers import XLNetForSequenceClassification\n","torch.manual_seed(0)\n","logging.set_verbosity_error()\n","#hyper-parameter tuning\n","learning_rates = [5e-5, 3e-5, 2e-5]\n","epoch_counts = [2]\n","batch_sizes = [16]\n","best_val_acc = -1\n","hyp_configs = [(lr, epochs, batch_size) for lr in learning_rates for epochs in epoch_counts for batch_size in batch_sizes]\n","\n","for cno, config in enumerate(hyp_configs):\n","  trial = cno + 1\n","  lr, epochs, batch_size = config\n","\n","  print(\"\")\n","  print (\"Trial %s: lr: %s  batch_size: %s  epochs: %s\" %(trial,lr, batch_size, epochs))\n","\n","  model = XLNetForSequenceClassification.from_pretrained(\n","    'xlnet-large-cased',\n","    num_labels = 10, # The number of output labels.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n","    )\n","\n","  # Tell pytorch to run this model on the GPU.\n","  model.cuda()\n","\n","  optimizer = AdamW(model.parameters(),\n","                  lr = lr, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n","                )\n","  \n","  solver_object = (model, optimizer, batch_size, epochs)\n","  current_val_acc, curr_batch_text, curr_batch_pred, curr_batch_labels = train2(solver_object, xlnet_train_set, xlnet_val_set)\n","  if current_val_acc>best_val_acc:\n","    best_val_acc = current_val_acc\n","    best_solver_object = solver_object\n","    best_hyperparams = (lr, batch_size, epochs)\n","    batch_text = curr_batch_text\n","    batch_pred = curr_batch_pred\n","    batch_labels = curr_batch_labels\n","\n","lr, batch_size, epochs = best_hyperparams\n","\n","print(\"Best hyperparameter configuration\")\n","print(f\"lr: {lr}  Batch Size: {batch_size}  Epochs: {epochs}\")\n","print(\"\")\n","print(\"Best Validation Accuracy = \", best_val_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ns-XOYP9ObzE","executionInfo":{"status":"ok","timestamp":1684369332329,"user_tz":240,"elapsed":10,"user":{"displayName":"Chirag Uday Kamath","userId":"13917471864390499412"}},"outputId":"37264a2a-d02d-47ea-f9ea-932a824d2f00"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 1: lr: 5e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 772.353452325671 Val Acc: 0.65252342435324688\n","Epoch #2/2 ** Total loss: 546.946372024234 Val Acc: 0.67419934402362847\n","\n","Trial 2: lr: 3e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 528.2914175093174 Val Acc: 0.7313939264463993\n","Epoch #2/2 ** Total loss: 318.3933340907097 Val Acc: 0.7294047426428033\n","\n","Trial 3: lr: 2e-05  batch_size: 16  epochs: 2\n","Epoch #1/2 ** Total loss: 532.8082787394524 Val Acc: 0.702378272643338\n","Epoch #2/2 ** Total loss: 313.2527703344822 Val Acc: 0.713567899836231\n","Best hyperparameter configuration\n","lr: 3e-05  Batch Size: 16  Epochs: 2\n","Best Validation Accuracy =  0.7313939264463993\n"]}]}]}